import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import cv2
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import os

# 1. VERÄ° HAZIRLAMA
def prepare_dataset(processed_data_dir, original_data_dir, img_size=224, validation_split=0.2):
    """Dataset'i yÃ¼kle ve train/val'e ayÄ±r"""
    processed_data_dir = Path(processed_data_dir)
    original_data_dir = Path(original_data_dir)

    # SÄ±nÄ±f isimlerini orijinal veri dizininden al
    class_names = sorted([d.name for d in original_data_dir.iterdir() if d.is_dir()])
    print(f"Bulunan sÄ±nÄ±flar: {class_names}")

    # Her sÄ±nÄ±ftan Ã¶rnek sayÄ±sÄ±nÄ± say (iÅŸlenmiÅŸ veriden)
    print("\nÄ°ÅŸlenmiÅŸ veri seti daÄŸÄ±lÄ±mÄ±:")
    for class_name in class_names:
        train_path = processed_data_dir / 'train' / class_name
        val_path = processed_data_dir / 'val' / class_name
        train_count = len(list(train_path.glob('*.jpg')) + list(train_path.glob('*.png')) + list(train_path.glob('*.jpeg')))
        val_count = len(list(val_path.glob('*.jpg')) + list(val_path.glob('*.png')) + list(val_path.glob('*.jpeg')))
        print(f"  {class_name}: Train {train_count}, Val {val_count}")


    # Data augmentation
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=30,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        vertical_flip=True,
        zoom_range=0.2,
        brightness_range=[0.8, 1.2],
        fill_mode='nearest'
    )

    # Train set
    train_generator = train_datagen.flow_from_directory(
        processed_data_dir / 'train',  # Ä°ÅŸlenmiÅŸ verinin train klasÃ¶rÃ¼
        target_size=(img_size, img_size),
        batch_size=32,
        class_mode='categorical',
        shuffle=True
    )

    # Validation set
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Val sette sadece rescale

    val_generator = val_datagen.flow_from_directory(
        processed_data_dir / 'val', # Ä°ÅŸlenmiÅŸ verinin val klasÃ¶rÃ¼
        target_size=(img_size, img_size),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )


    return train_generator, val_generator, class_names

# 2. MODEL OLUÅTURMA
def create_model(num_classes, img_size=224):
    """Global Average Pooling kullanan model (CAM iÃ§in gerekli)"""
    base = keras.applications.EfficientNetB0(
        include_top=False,
        weights='imagenet',
        input_shape=(img_size, img_size, 3)
    )

    # Ä°lk katmanlarÄ± dondur
    base.trainable = False

    inputs = keras.Input(shape=(img_size, img_size, 3))
    x = base(inputs, training=False)

    # CAM iÃ§in Global Average Pooling kullan
    x = layers.GlobalAveragePooling2D(name='gap')(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)

    model = keras.Model(inputs, outputs)
    return model, base

# 3. GRAD-CAM Ä°MPLEMENTASYONU
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    """Grad-CAM Ä±sÄ± haritasÄ± oluÅŸtur"""
    # Model iÃ§in preprocessing
    # img_array already preprocessed by flow_from_directory (rescale)
    # keras.applications.efficientnet.preprocess_input(img_array)

    grad_model = keras.models.Model(
        model.inputs,
        [model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

# 4. OPENCV Ä°LE GÃ–RSELLEÅTIRME
def overlay_heatmap_on_image(img, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):
    """IsÄ± haritasÄ±nÄ± gÃ¶rÃ¼ntÃ¼ Ã¼zerine bindirin"""
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, colormap)

    # GÃ¶rÃ¼ntÃ¼yÃ¼ birleÅŸtir
    superimposed = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)
    return superimposed, heatmap

def mark_disease_region(img, heatmap, threshold=0.6):
    """HastalÄ±k bÃ¶lgesini bbox ve kontur ile iÅŸaretleyin"""
    img_marked = img.copy()

    # IsÄ± haritasÄ±nÄ± resize et
    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))

    # EÅŸikleme uygula
    _, binary = cv2.threshold(
        (heatmap_resized * 255).astype(np.uint8),
        int(threshold * 255),
        255,
        cv2.THRESH_BINARY
    )

    # Morfolojik iÅŸlemler (gÃ¼rÃ¼ltÃ¼yÃ¼ azalt)
    kernel = np.ones((5, 5), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)

    # KonturlarÄ± bul
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # KonturlarÄ± bÃ¼yÃ¼klÃ¼ÄŸe gÃ¶re sÄ±rala ve en bÃ¼yÃ¼k 3'Ã¼nÃ¼ al
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]

    # Her konturu iÅŸaretle
    for i, contour in enumerate(contours):
        if cv2.contourArea(contour) > 100:  # Ã‡ok kÃ¼Ã§Ã¼k alanlarÄ± yoksay
            # Bounding box Ã§iz
            x, y, w, h = cv2.boundingRect(contour)
            cv2.rectangle(img_marked, (x, y), (x+w, y+h), (0, 255, 0), 3)

            # Konturu Ã§iz
            cv2.drawContours(img_marked, [contour], -1, (255, 0, 0), 2)

            # Alan bilgisini yaz
            area_pct = (cv2.contourArea(contour) / (img.shape[0] * img.shape[1])) * 100
            cv2.putText(img_marked, f'{area_pct:.1f}%', (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    return img_marked

# 5. TAM PIPELINE
def process_image(image_path, model, class_names, img_size=224):
    """Tam iÅŸleme pipeline'Ä±"""
    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError(f"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {image_path}")

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Model iÃ§in hazÄ±rla
    img_resized = cv2.resize(img_rgb, (img_size, img_size))
    img_array = np.expand_dims(img_resized, axis=0).astype(np.float32)

    # Tahmin yap (preprocessing burada yapÄ±lacak)
    img_preprocessed = keras.applications.efficientnet.preprocess_input(img_array.copy())
    predictions = model.predict(img_preprocessed, verbose=0)
    pred_class = np.argmax(predictions[0])
    confidence = predictions[0][pred_class]

    # Top 3 tahmini al
    top3_idx = np.argsort(predictions[0])[-3:][::-1]
    top3_predictions = [(class_names[i], predictions[0][i]) for i in top3_idx]

    # Grad-CAM hesapla
    last_conv_layer = 'top_activation'
    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer, pred_class)

    # GÃ¶rselleÅŸtir
    superimposed, heatmap_colored = overlay_heatmap_on_image(img_rgb, heatmap)
    marked = mark_disease_region(img_rgb, heatmap, threshold=0.5)

    return {
        'original': img_rgb,
        'heatmap_overlay': superimposed,
        'marked': marked,
        'prediction': class_names[pred_class],
        'confidence': confidence,
        'top3': top3_predictions,
        'heatmap': heatmap
    }

# 6. GÃ–RSELLEÅTIRME
def visualize_results(results, save_path=None):
    """SonuÃ§larÄ± gÃ¶ster"""
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    axes[0].imshow(results['original'])
    axes[0].set_title('Orijinal GÃ¶rÃ¼ntÃ¼', fontsize=14, fontweight='bold')
    axes[0].axis('off')

    axes[1].imshow(results['heatmap_overlay'])
    axes[1].set_title('Grad-CAM IsÄ± HaritasÄ±', fontsize=14, fontweight='bold')
    axes[1].axis('off')

    # Top 3 tahmini gÃ¶ster
    top3_text = '\n'.join([f"{name}: {conf:.1%}" for name, conf in results['top3']])
    axes[2].imshow(results['marked'])
    axes[2].set_title(f"Ä°ÅŸaretlenmiÅŸ BÃ¶lge\n{results['prediction']} ({results['confidence']:.1%})\n\nTop 3:\n{top3_text}",
                     fontsize=12, fontweight='bold')
    axes[2].axis('off')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"SonuÃ§ kaydedildi: {save_path}")

    plt.show()

# 7. EÄÄ°TÄ°M FONKSÄ°YONU
def train_model(processed_data_dir, original_data_dir, epochs=30, img_size=224):
    """Model eÄŸitimi"""
    print("=" * 60)
    print("VERÄ° SETÄ° HAZIRLANIYOR...")
    print("=" * 60)

    # Veri setini hazÄ±rla
    train_gen, val_gen, class_names = prepare_dataset(processed_data_dir, original_data_dir, img_size)
    num_classes = len(class_names)

    print(f"\nToplam sÄ±nÄ±f sayÄ±sÄ±: {num_classes}")
    print(f"Train Ã¶rnekleri: {train_gen.samples}")
    print(f"Validation Ã¶rnekleri: {val_gen.samples}")

    # Model oluÅŸtur
    print("\n" + "=" * 60)
    print("MODEL OLUÅTURULUYOR...")
    print("=" * 60)
    model, base = create_model(num_classes, img_size)
    model.summary()

    # Compile
    model.compile(
        optimizer=keras.optimizers.Adam(1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]
    )

    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            verbose=1,
            min_lr=1e-7
        ),
        keras.callbacks.ModelCheckpoint(
            'best_model.h5',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]

    # Ä°lk eÄŸitim (frozen base)
    print("\n" + "=" * 60)
    print("PHASE 1: TRANSFER LEARNING (Frozen Base)")
    print("=" * 60)
    history1 = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=epochs // 2,
        callbacks=callbacks,
        verbose=1
    )

    # Fine-tuning
    print("\n" + "=" * 60)
    print("PHASE 2: FINE-TUNING (Unfrozen Base)")
    print("=" * 60)
    base.trainable = True

    # Son 50 katmanÄ± unfreeze et
    for layer in base.layers[:-50]:
        layer.trainable = False

    model.compile(
        optimizer=keras.optimizers.Adam(1e-5),
        loss='categorical_crossentropy',
        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]
    )

    history2 = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=epochs // 2,
        callbacks=callbacks,
        verbose=1
    )

    # Son modeli kaydet
    model.save('skin_disease_model_final.h5')
    print(f"\nModel kaydedildi: skin_disease_model_final.h5")

    # SÄ±nÄ±f isimlerini kaydet
    with open('class_names.txt', 'w', encoding='utf-8') as f:
        for name in class_names:
            f.write(f"{name}\n")
    print(f"SÄ±nÄ±f isimleri kaydedildi: class_names.txt")

    # EÄŸitim grafiklerini Ã§iz
    plot_training_history(history1, history2)

    return model, class_names

# 8. EÄÄ°TÄ°M GRAFÄ°KLERÄ°
def plot_training_history(history1, history2):
    """EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    # Accuracy
    axes[0].plot(history1.history['accuracy'], label='Train (Phase 1)')
    axes[0].plot(history1.history['val_accuracy'], label='Val (Phase 1)')
    axes[0].plot(range(len(history1.history['accuracy']),
                      len(history1.history['accuracy']) + len(history2.history['accuracy'])),
                history2.history['accuracy'], label='Train (Phase 2)')
    axes[0].plot(range(len(history1.history['val_accuracy']),
                      len(history1.history['val_accuracy']) + len(history2.history['val_accuracy'])),
                history2.history['val_accuracy'], label='Val (Phase 2)')
    axes[0].set_title('Model Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Accuracy')
    axes[0].legend()
    axes[0].grid(True)

    # Loss
    axes[1].plot(history1.history['loss'], label='Train (Phase 1)')
    axes[1].plot(history1.history['val_loss'], label='Val (Phase 1)')
    axes[1].plot(range(len(history1.history['loss']),
                      len(history1.history['loss']) + len(history2.history['loss'])),
                history2.history['loss'], label='Train (Phase 2)')
    axes[1].plot(range(len(history1.history['val_loss']),
                      len(history1.history['val_loss']) + len(history2.history['val_loss'])),
                history2.history['val_loss'], label='Val (Phase 2)')
    axes[1].set_title('Model Loss')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Loss')
    axes[1].legend()
    axes[1].grid(True)

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150)
    plt.show()

# 9. TOPLU TEST
def batch_test(test_dir, model, class_names, num_images=5):
    """Birden fazla gÃ¶rÃ¼ntÃ¼yÃ¼ test et"""
    test_images = list(Path(test_dir).rglob('*.jpg')) + \
                  list(Path(test_dir).rglob('*.png')) + \
                  list(Path(test_dir).rglob('*.jpeg'))

    test_images = test_images[:num_images]

    for img_path in test_images:
        print(f"\n{'='*60}")
        print(f"Test: {img_path.name}")
        print(f"{'='*60}")

        results = process_image(img_path, model, class_names)
        visualize_results(results, save_path=f'result_{img_path.stem}.png')

# =============================================================================
# KULLANIM KILAVUZU
# =============================================================================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     CÄ°LT HASTALIÄI SINIFLANDIRMA VE LOKALÄ°ZASYON SÄ°STEMÄ°         â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    KULLANIM ADIMLARI:

    1ï¸âƒ£  MODEL EÄÄ°TÄ°MÄ°:
        model, class_names = train_model('/content/dataset/processed', '/content/dataset/IMG_CLASSES', epochs=30) # Ä°ÅŸlenmiÅŸ ve orijinal veri klasÃ¶rlerini kullan

    2ï¸âƒ£  TEK GÃ–RÃœNTÃœ TESTÄ°:
        results = process_image('test.jpg', model, class_names)
        visualize_results(results)

    3ï¸âƒ£  TOPLU TEST:
        batch_test('/content/dataset/processed/val', model, class_names, num_images=10) # Ä°ÅŸlenmiÅŸ validation setini kullan

    4ï¸âƒ£  MODELÄ° YÃœKLEME (sonraki kullanÄ±mlar iÃ§in):
        model = keras.models.load_model('skin_disease_model_final.h5')
        with open('class_names.txt', 'r', encoding='utf-8') as f:
            class_names = [line.strip() for line in f.readlines()]

    5ï¸âƒ£  SONUÃ‡LARI KAYDETME:
        results = process_image('test.jpg', model, class_names)
        cv2.imwrite('marked_result.jpg', cv2.cvtColor(results['marked'], cv2.COLOR_RGB2BGR))
    """)

    # OTOMATIK Ã‡ALIÅTIRMA
    SOURCE_DATA_DIR = '/content/dataset/IMG_CLASSES' # Orijinal veri klasÃ¶rÃ¼
    PROCESSED_DATA_DIR = '/content/dataset/processed' # Ä°ÅŸlenmiÅŸ veri klasÃ¶rÃ¼

    if os.path.exists(PROCESSED_DATA_DIR):
        print(f"\nâœ… Ä°ÅŸlenmiÅŸ veri seti bulundu: {PROCESSED_DATA_DIR}")
        print("\nğŸš€ EÄŸitim baÅŸlatÄ±lÄ±yor...\n")

        # Modeli eÄŸit - Ä°ÅŸlenmiÅŸ ve orijinal veri klasÃ¶rlerini kullan
        model, class_names = train_model(PROCESSED_DATA_DIR, SOURCE_DATA_DIR, epochs=30)

        print("\n" + "="*60)
        print("âœ… EÄÄ°TÄ°M TAMAMLANDI!")
        print("="*60)
        print(f"\nKaydedilen dosyalar:")
        print("  ğŸ“ skin_disease_model_final.h5")
        print("  ğŸ“ best_model.h5")
        print("  ğŸ“ class_names.txt")
        print("  ğŸ“ training_history.png")

    else:
        print(f"\nâŒ Ä°ÅŸlenmiÅŸ veri seti bulunamadÄ±: {PROCESSED_DATA_DIR}")
        print("LÃ¼tfen Ã¶n iÅŸleme kodunun tamamlandÄ±ÄŸÄ±ndan ve 'processed' klasÃ¶rÃ¼nÃ¼n oluÅŸtuÄŸundan emin olun.")